import os
import sys
import json
import time
from typing import Any, Dict, List
# ç§»é™¤Flaskå¯¼å…¥ï¼Œä½¿ç”¨ç®€å•çš„Responseç±»
# from flask import Response, stream_with_context

# Add the project root to the Python path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from ..lib.logger import logger
from ..lib.util import uuid_generator, unix_timestamp
from ..lib.exceptions.api_exception import APIException
from ..lib.consts.exceptions import EX
from .images import generate_images, generate_image_composition, DEFAULT_MODEL
from .videos import generate_video, DEFAULT_MODEL as DEFAULT_VIDEO_MODEL

# åˆ›å»ºç®€å•çš„Responseç±»æ¥æ›¿ä»£Flaskçš„Response
class Response:
    def __init__(self, response=None, status=None, headers=None, mimetype=None):
        self.response = response
        self.status = status
        self.headers = headers or {}
        self.mimetype = mimetype

# é»˜è®¤æ¨¡å‹
DEFAULT_CHAT_MODEL = DEFAULT_MODEL

def parse_model(model: str) -> Dict[str, Any]:
    """è§£ææ¨¡å‹"""
    parts = model.split(":")
    _model = parts[0]
    
    width = 1024
    height = 1024
    
    if len(parts) > 1:
        size_parts = parts[1].split("x")
        if len(size_parts) == 2:
            try:
                width = int(size_parts[0])
                height = int(size_parts[1])
                # ç¡®ä¿å®½é«˜æ˜¯å¶æ•°
                width = (width + 1) // 2 * 2
                height = (height + 1) // 2 * 2
            except ValueError:
                pass
    
    return {
        "model": _model,
        "width": width,
        "height": height,
    }

def is_video_model(model: str) -> bool:
    """æ£€æµ‹æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆè¯·æ±‚"""
    return model.startswith("jimeng-video")

def create_completion(
    messages: List[Dict[str, Any]],
    refresh_token: str,
    _model: str = DEFAULT_CHAT_MODEL,
    retry_count: int = 0
) -> Dict[str, Any]:
    """åŒæ­¥å¯¹è¯è¡¥å…¨"""
    try:
        if len(messages) == 0:
            raise APIException(EX.API_REQUEST_PARAMS_INVALID, "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")

        model_info = parse_model(_model)
        model_name = model_info["model"]
        width = model_info["width"]
        height = model_info["height"]
        
        logger.info(f"Messages: {json.dumps(messages, ensure_ascii=False)}")
        logger.info(f"Model info: model={model_name}, width={width}, height={height}")

        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆè¯·æ±‚
        if is_video_model(_model):
            try:
                # è§†é¢‘ç”Ÿæˆ
                logger.info(f"å¼€å§‹ç”Ÿæˆè§†é¢‘ï¼Œæ¨¡å‹: {_model}")
                
                video_url = generate_video(
                    _model,
                    messages[-1]["content"],
                    {
                        "width": width,
                        "height": height,
                        "resolution": "720p",  # é»˜è®¤åˆ†è¾¨ç‡
                    },
                    refresh_token
                )

                logger.info(f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼ŒURL: {video_url}")
                return {
                    "id": uuid_generator(),
                    "model": _model,
                    "object": "chat.completion",
                    "choices": [
                        {
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": f"![video]({video_url})\n",
                            },
                            "finish_reason": "stop",
                        },
                    ],
                    "usage": {"prompt_tokens": 1, "completion_tokens": 1, "total_tokens": 2},
                    "created": unix_timestamp(),
                }
            except APIException:
                raise
            except Exception as e:
                logger.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
                return {
                    "id": uuid_generator(),
                    "model": _model,
                    "object": "chat.completion",
                    "choices": [
                        {
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": f"ç”Ÿæˆè§†é¢‘å¤±è´¥: {str(e)}\n\nå¦‚æœæ‚¨åœ¨å³æ¢¦å®˜ç½‘çœ‹åˆ°å·²ç”Ÿæˆçš„è§†é¢‘ï¼Œå¯èƒ½æ˜¯è·å–ç»“æœæ—¶å‡ºç°äº†é—®é¢˜ï¼Œè¯·å‰å¾€å³æ¢¦å®˜ç½‘æŸ¥çœ‹ã€‚",
                            },
                            "finish_reason": "stop",
                        },
                    ],
                    "usage": {"prompt_tokens": 1, "completion_tokens": 1, "total_tokens": 2},
                    "created": unix_timestamp(),
                }
        else:
            # å›¾åƒç”Ÿæˆ
            logger.info(f"å¼€å§‹ç”Ÿæˆå›¾åƒï¼Œæ¨¡å‹: {model_name}, æç¤ºè¯: {messages[-1]['content']}")
            image_urls = generate_images(
                model_name,
                messages[-1]["content"],
                {
                    "width": width,
                    "height": height,
                },
                refresh_token
            )
            logger.info(f"å›¾åƒç”Ÿæˆå®Œæˆï¼ŒURLs: {image_urls}")

            return {
                "id": uuid_generator(),
                "model": _model or model_name,
                "object": "chat.completion",
                "choices": [
                    {
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": "".join([f"![image_{i}]({url})\n" for i, url in enumerate(image_urls)]),
                        },
                        "finish_reason": "stop",
                    },
                ],
                "usage": {"prompt_tokens": 1, "completion_tokens": 1, "total_tokens": 2},
                "created": unix_timestamp(),
            }
    except Exception as e:
        logger.error(f"Response error: {str(e)}")
        logger.error(f"Error type: {type(e)}")
        if retry_count < 3:  # æœ€å¤šé‡è¯•3æ¬¡
            logger.warn(f"Try again after 2s...")
            time.sleep(2)
            return create_completion(messages, refresh_token, _model, retry_count + 1)
        raise e

def create_completion_stream(
    messages: List[Dict[str, Any]],
    refresh_token: str,
    _model: str = DEFAULT_CHAT_MODEL,
    retry_count: int = 0
) -> Response:
    """æµå¼å¯¹è¯è¡¥å…¨"""
    
    def generate():
        try:
            model_info = parse_model(_model)
            model_name = model_info["model"]
            width = model_info["width"]
            height = model_info["height"]
            
            logger.info(f"Messages: {json.dumps(messages, ensure_ascii=False)}")

            if len(messages) == 0:
                logger.warn("æ¶ˆæ¯ä¸ºç©ºï¼Œè¿”å›ç©ºæµ")
                yield "data: [DONE]\n\n"
                return

            # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆè¯·æ±‚
            if is_video_model(_model):
                # è§†é¢‘ç”Ÿæˆ
                yield "data: " + json.dumps({
                    "id": uuid_generator(),
                    "model": _model,
                    "object": "chat.completion.chunk",
                    "choices": [
                        {
                            "index": 0,
                            "delta": {"role": "assistant", "content": "ğŸ¬ è§†é¢‘ç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™...\nè¿™å¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…"},
                            "finish_reason": None,
                        },
                    ],
                }) + "\n\n"

                # å‘é€è¿›åº¦ç‚¹
                for i in range(24):  # æ¨¡æ‹Ÿ2åˆ†é’Ÿçš„è¿›åº¦
                    time.sleep(5)
                    yield "data: " + json.dumps({
                        "id": uuid_generator(),
                        "model": _model,
                        "object": "chat.completion.chunk",
                        "choices": [
                            {
                                "index": 0,
                                "delta": {"role": "assistant", "content": "."},
                                "finish_reason": None,
                            },
                        ],
                    }) + "\n\n"

                try:
                    logger.info(f"å¼€å§‹ç”Ÿæˆè§†é¢‘ï¼Œæ¨¡å‹: {_model}, æç¤ºè¯: {messages[-1]['content'][:50]}...")
                    
                    # å…ˆç»™ç”¨æˆ·ä¸€ä¸ªåˆå§‹æç¤º
                    yield "data: " + json.dumps({
                        "id": uuid_generator(),
                        "model": _model,
                        "object": "chat.completion.chunk",
                        "choices": [
                            {
                                "index": 0,
                                "delta": {
                                    "role": "assistant",
                                    "content": "\n\nğŸ¬ è§†é¢‘ç”Ÿæˆå·²å¼€å§‹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...",
                                },
                                "finish_reason": None,
                            },
                        ],
                    }) + "\n\n"

                    video_url = generate_video(
                        _model,
                        messages[-1]["content"],
                        {"width": width, "height": height, "resolution": "720p"},
                        refresh_token
                    )

                    logger.info(f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼ŒURL: {video_url}")

                    yield "data: " + json.dumps({
                        "id": uuid_generator(),
                        "model": _model,
                        "object": "chat.completion.chunk",
                        "choices": [
                            {
                                "index": 1,
                                "delta": {
                                    "role": "assistant",
                                    "content": f"\n\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼\n\n![video]({video_url})\n\næ‚¨å¯ä»¥ï¼š\n1. ç›´æ¥æŸ¥çœ‹ä¸Šæ–¹è§†é¢‘\n2. ä½¿ç”¨ä»¥ä¸‹é“¾æ¥ä¸‹è½½æˆ–åˆ†äº«ï¼š{video_url}",
                                },
                                "finish_reason": None,
                            },
                        ],
                    }) + "\n\n"

                    yield "data: " + json.dumps({
                        "id": uuid_generator(),
                        "model": _model,
                        "object": "chat.completion.chunk",
                        "choices": [
                            {
                                "index": 2,
                                "delta": {
                                    "role": "assistant",
                                    "content": "",
                                },
                                "finish_reason": "stop",
                            },
                        ],
                    }) + "\n\n"
                    yield "data: [DONE]\n\n"
                except Exception as err:
                    logger.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(err)}")
                    logger.error(f"é”™è¯¯è¯¦æƒ…: {str(err)}")

                    # æ„å»ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    error_message = f"âš ï¸ è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜: {str(err)}"

                    # å¦‚æœæ˜¯å†å²è®°å½•ä¸å­˜åœ¨çš„é”™è¯¯ï¼Œæä¾›æ›´å…·ä½“çš„å»ºè®®
                    if "å†å²è®°å½•ä¸å­˜åœ¨" in str(err):
                        error_message += "\n\nå¯èƒ½åŸå› ï¼š\n1. è§†é¢‘ç”Ÿæˆè¯·æ±‚å·²å‘é€ï¼Œä½†APIæ— æ³•è·å–å†å²è®°å½•\n2. è§†é¢‘ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n3. å†å²è®°å½•IDæ— æ•ˆæˆ–å·²è¿‡æœŸ\n\nå»ºè®®æ“ä½œï¼š\n1. è¯·å‰å¾€å³æ¢¦å®˜ç½‘æŸ¥çœ‹æ‚¨çš„è§†é¢‘æ˜¯å¦å·²ç”Ÿæˆï¼šhttps://jimeng.jianying.com/ai-tool/video/generate\n2. å¦‚æœå®˜ç½‘å·²æ˜¾ç¤ºè§†é¢‘ï¼Œä½†è¿™é‡Œæ— æ³•è·å–ï¼Œå¯èƒ½æ˜¯APIè¿æ¥é—®é¢˜\n3. å¦‚æœå®˜ç½‘ä¹Ÿæ²¡æœ‰æ˜¾ç¤ºï¼Œè¯·ç¨åå†è¯•æˆ–é‡æ–°ç”Ÿæˆè§†é¢‘"
                    elif "è·å–è§†é¢‘ç”Ÿæˆç»“æœè¶…æ—¶" in str(err):
                        error_message += "\n\nè§†é¢‘ç”Ÿæˆå¯èƒ½ä»åœ¨è¿›è¡Œä¸­ï¼Œä½†ç­‰å¾…æ—¶é—´å·²è¶…è¿‡ç³»ç»Ÿè®¾å®šçš„é™åˆ¶ã€‚\n\nè¯·å‰å¾€å³æ¢¦å®˜ç½‘æŸ¥çœ‹æ‚¨çš„è§†é¢‘ï¼šhttps://jimeng.jianying.com/ai-tool/video/generate\n\nå¦‚æœæ‚¨åœ¨å®˜ç½‘ä¸Šçœ‹åˆ°è§†é¢‘å·²ç”Ÿæˆï¼Œä½†è¿™é‡Œæ— æ³•æ˜¾ç¤ºï¼Œå¯èƒ½æ˜¯å› ä¸ºï¼š\n1. è·å–ç»“æœçš„è¿‡ç¨‹è¶…æ—¶\n2. ç½‘ç»œè¿æ¥é—®é¢˜\n3. APIè®¿é—®é™åˆ¶"
                    else:
                        error_message += "\n\nå¦‚æœæ‚¨åœ¨å³æ¢¦å®˜ç½‘çœ‹åˆ°å·²ç”Ÿæˆçš„è§†é¢‘ï¼Œå¯èƒ½æ˜¯è·å–ç»“æœæ—¶å‡ºç°äº†é—®é¢˜ã€‚\n\nè¯·è®¿é—®å³æ¢¦å®˜ç½‘æŸ¥çœ‹æ‚¨çš„åˆ›ä½œå†å²ï¼šhttps://jimeng.jianying.com/ai-tool/video/generate"

                    yield "data: " + json.dumps({
                        "id": uuid_generator(),
                        "model": _model,
                        "object": "chat.completion.chunk",
                        "choices": [
                            {
                                "index": 1,
                                "delta": {
                                    "role": "assistant",
                                    "content": f"\n\n{error_message}",
                                },
                                "finish_reason": "stop",
                            },
                        ],
                    }) + "\n\n"
                    yield "data: [DONE]\n\n"
            else:
                # å›¾åƒç”Ÿæˆ
                yield "data: " + json.dumps({
                    "id": uuid_generator(),
                    "model": _model or model_name,
                    "object": "chat.completion.chunk",
                    "choices": [
                        {
                            "index": 0,
                            "delta": {"role": "assistant", "content": "ğŸ¨ å›¾åƒç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™..."},
                            "finish_reason": None,
                        },
                    ],
                }) + "\n\n"

                try:
                    image_urls = generate_images(
                        model_name,
                        messages[-1]["content"],
                        {"width": width, "height": height},
                        refresh_token
                    )

                    for i, url in enumerate(image_urls):
                        yield "data: " + json.dumps({
                            "id": uuid_generator(),
                            "model": _model or model_name,
                            "object": "chat.completion.chunk",
                            "choices": [
                                {
                                    "index": i + 1,
                                    "delta": {
                                        "role": "assistant",
                                        "content": f"![image_{i}]({url})\n",
                                    },
                                    "finish_reason": "stop" if i == len(image_urls) - 1 else None,
                                },
                            ],
                        }) + "\n\n"
                    
                    yield "data: " + json.dumps({
                        "id": uuid_generator(),
                        "model": _model or model_name,
                        "object": "chat.completion.chunk",
                        "choices": [
                            {
                                "index": len(image_urls) + 1,
                                "delta": {
                                    "role": "assistant",
                                    "content": "å›¾åƒç”Ÿæˆå®Œæˆï¼",
                                },
                                "finish_reason": "stop",
                            },
                        ],
                    }) + "\n\n"
                    yield "data: [DONE]\n\n"
                except Exception as err:
                    yield "data: " + json.dumps({
                        "id": uuid_generator(),
                        "model": _model or model_name,
                        "object": "chat.completion.chunk",
                        "choices": [
                            {
                                "index": 1,
                                "delta": {
                                    "role": "assistant",
                                    "content": f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {str(err)}",
                                },
                                "finish_reason": "stop",
                            },
                        ],
                    }) + "\n\n"
                    yield "data: [DONE]\n\n"
        except Exception as e:
            if retry_count < 3:  # æœ€å¤šé‡è¯•3æ¬¡
                logger.error(f"Response error: {str(e)}")
                logger.warn(f"Try again after 2s...")
                time.sleep(2)
                # é‡æ–°ç”Ÿæˆæµ
                for chunk in generate():
                    yield chunk
            else:
                yield "data: " + json.dumps({
                    "id": uuid_generator(),
                    "model": _model,
                    "object": "chat.completion.chunk",
                    "choices": [
                        {
                            "index": 0,
                            "delta": {
                                "role": "assistant",
                                "content": f"è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}",
                            },
                            "finish_reason": "stop",
                        },
                    ],
                }) + "\n\n"
                yield "data: [DONE]\n\n"

    # è¿”å›ä¸€ä¸ªç®€å•çš„Responseå¯¹è±¡è€Œä¸æ˜¯Flask Response
    return Response(generate(), mimetype='text/event-stream')